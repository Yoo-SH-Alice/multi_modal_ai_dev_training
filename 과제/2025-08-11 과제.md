
## 생성형 AI 동작원리

생성형 AI는 **새로운 콘텐츠를 만들어내는 인공지능 기술 전반**을 의미합니다

### 모델 생성 과정
생성형 AI 동작과정은 크게 학습, 추론 , 배포 이렇게 세 단계로 나누어집니다. 이 과정에서 텍스트, 오디오, 이미지 등 다양한 종류의 콘텐츠를 생성할 수 있게 됩니다.

##### 학습(Training)
모델이 데이터를 습득하는 과정입니다. 많은 량의 데이터(텍스트, 문서, 이미지 등) 모델에 입력해서 패턴을 학습합니다. 

- 데이터 수집 및 전처리 : 모델에 적합한 데이터를 모으고 학습하기 좋은 형태로 정제 및 정리
- 모델 구조 설계 : 어떤 종류의 AI 모델을 사용할지 결정.
- 학습 : 준비된 데이터를 모델에 반복적으로 입력. 이 과정에서 데이터의 패턴과 통계적 관계를 파악하며 예측 정확도를 높이기 우히나 매개변수를 계속 조정

##### 추론(Inference)
학습을 끝낸 모델이 새로운 데이터를 생성할 수 있는 단계입니다. 프롬프트로 입력을 하면 그에 따른 출력을 생성하여 결과를 출력합니다.

-  프롬프트 입력 : 사용자가 텍스트나 이미지 등 원하는 결과물의 방향을 제시하는 입력값
- 결과물 생성 : 입력한 프롬프트에 적합한 새로운 결과물을 생성
- 후처리 : 생성된 결과물이 사용자의 요구에 적합하도록 보정하는 작업

##### 배포 (Deployment)
- 최적화
- 인터페이스 구축 : 사용자가 모델과 상호작용을 하기 위한 웹페이지와 같은 프로그래밍 인터페이스를 만듬
- 지속적인 모니터링 및 업데이트 : 배포 후에도 모델의 성능을 지속적으로 모니터링하고, 새로운 데이터로 재학습하여 모델의 성능을 개선하는 작업을 진행

### 동작 원리
학습된 데이터의 **패턴과 규칙을 바탕으로 새로운 데이터를 예측하고 생성**하는 방식으로 작동합니다. 마치 사람의 뇌가 여러 정보를 조합해 새로운 생각을 만들어내듯, AI는 방대한 양의 데이터를 학습하여 그 데이터의 통계적 구조와 관계를 파악한 후, 이를 활용해 새로운 결과물을 만들어냅니다. 이 원리는 이미지, 영상 등 여러 형태의 컨텐츠를 생성하든 동일 합니다

##### 예측 기반 생성 원리를 구현하는 다양한 기술 모델
 GAN (Generative Adversarial Network)
 트랜스포머 (Transformer)
 확산 모델 (Diffusion Models)
 
---
## LLM과 API의 개념 및 관계 파악

### LLM이란?
**방대한 양의 텍스트 데이터를 학습하여 텍스트 기반의 작업을 수행하도록 설계된 생성형 AI의 한 종류**입니다.

### API란?
소프트웨어 애플리케이션들이 서로 통신하고 상호작용할 수 있도록 하는 규칙, 프로토콜, 도구들의 집합 입니다. API는 서로 다른 소프트웨어 시스템들이 마치 번역가처럼 대화할 수 있도록 돕는 매개체 역할을 합니다. LLM의 경우, 개발자는 A

### LLM과 API
LLM의 경우, 개발자는 API를 통해 모델에 텍스트를 전달하고, 모델이 생성한 응답을 다시 받게 됩니다. API는 LLM을 직접 다루지 않고도 그 기능을 활용할 수 있는 표준화된 통로를 제공합니다. 이를 통해 복잡한 AI 시스템 개발 없이도 자연어 처리 도구를 활용하여 사용자 경험을 향상시킬 수 있습니다.

LLM 자체에 대한 전문 지식이 없는 개발자도 API를 사용해 강력한 언어 모델의 기능을 자신의 서비스에 쉽게 통합할 수 있습니다. API는 LLM이라는 **기술을 제품이나 서비스로 구현할 수 있게 해주는 도구**입니다.

##### 실제 작동 방식
1. **개발자 요청**: 개발자는 자신의 애플리케이션(예: 챗봇, 번역기)에서 사용자의 질문(프롬프트)을 **LLM API**로 보냅니다. 이 요청은 보통 `JSON` 같은 정해진 형식으로 구성됩니다.
    
2. **API 서버 통신**: API 서버는 이 요청을 받아 LLM 모델에 전달합니다.
    
3.  **LLM 처리**: LLM은 전달받은 프롬프트를 분석하고, 학습된 지식을 바탕으로 가장 적절한 답변을 생성합니다.
    
4. **결과 반환**: 생성된 답변은 다시 API 서버를 거쳐 개발자의 애플리케이션으로 전달됩니다.
    
5. **사용자 응답**: 애플리케이션은 받은 답변을 사용자에게 보여줍니다  


----
##  LangChain, OpenAI API, Gemini API의 역할

생성형 AI를 활용하기 위한 도구이지만 LangChain과 OpenAI API, Gemini API는 상호 보완 관계입니다.
### OpenAI API
OpenAI가 제공하는 다양한 모델(GPT-4, DAlLL-E 등)에 접근할 수 있도록 만들어진 통신 인터페이스 입니다

### Gemini API
Google의  멀티모달 LLM인 Gemini 모델에 접근하기 위한 통로입니다.  텍스트, 이미지, 오디오, 영상을 입력받아 처리하는 멀티모달 기능이 특징 입니다.

### LangChain
**LLM을 활용해 복잡한 애플리케이션을 쉽게 만들도록 돕는 도구 모음(프레임워크)** 입니다. LangChain은 OpenAI API나 Gemini API와 같은 다양한 LLM API를 연결하고, 여러 단계를 체인(Chain)으로 묶어 복잡한 작업을 수행할 수 있게 해줍니다.

##### 주요기능
- Chains : 여러 작업을 순차적으로 연결하여 복잡한 프로세스를 자동화함
- Retrieval : 외부데이터(PDF문서, 웹사이트 등)를 연결하여 모델이 학습하지 않은 정보를 활용할 수 있게 함
- Agent : LLM이 상황에 따라 어떤 도구를 활용할지 스스로 판단하게 하여 외부 시스템과 상호 작용하도록함


---

## 공식문서 둘러보기

[Google AI for Developer](https://ai.google.dev/gemini-api/docs?hl=ko&_gl=1*vc57i1*_up*MQ..*_ga*MzgzMTc2NTg5LjE3NTQ4NzU5MDg.*_ga_P1DBVKWT6V*czE3NTQ5MDczNTAkbzIkZzAkdDE3NTQ5MDczNTAkajYwJGwwJGgyMTAyODE1MjQ5)

### 텍스트 생성
generate_content : 단일 텍스트 입력 사용
generate_content_stream : 인스턴스를 생성되는 대로 점진적으로 수신
chats : 멀티턴 대화 

### Thinking

사고 기능은 모든 2.5 시리즈 모델에서 지원

**thinking budget을 제한**
```
thinking_config=types.ThinkingConfig(thinking_budget=1024)
```
**thinking mode 끄기**
⚠️Pro 모델은 Thinkin mode를 끄는게 불가능함
```
# Turn off thinking:
thinking_config=types.ThinkingConfig(thinking_budget=0)
```

**thinking budget 자동설정**
```
# Turn on dynamic thinking:
thinking_config=types.ThinkingConfig(thinking_budget=-1)
```

### Google 검색으로 그라운딩
Gemini 모델을 실시간 웹 콘텐츠에 연결하며 사용 가능한 모든 언어로 작동


**Tool을 설정**
```
# Define the grounding tool
grounding_tool = types.Tool(
    google_search=types.GoogleSearch()
)
```


### 음성생성
단일 화자 또는 다중 화자 오디오로 변환 가능
자연어를 사용하여 상호작용을 구성하고 오디오의 스타일, 억양, 속도, 어조 등 설정 가능
```
response = client.models.generate_content(
   model="gemini-2.5-flash-preview-tts",
   contents="Say cheerfully: Have a wonderful day!",
   config=types.GenerateContentConfig(
      response_modalities=["AUDIO"],
      speech_config=types.SpeechConfig(
         voice_config=types.VoiceConfig(
            prebuilt_voice_config=types.PrebuiltVoiceConfig(
               voice_name='Kore',
            )
         )
      ),
   )
)
```


### 영상 생성
8초분량, 720P 동영상을 생성
```
operation = client.models.generate_videos(
    model="veo-3.0-generate-preview",
    prompt=prompt,
)

```
---

### 실습 코드정리
[Colab 소스코드](https://colab.research.google.com/drive/1k-LzhlqsXY-0_ooEiqYqGXU8kxrU0z7f?usp=sharing)